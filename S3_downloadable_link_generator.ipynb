{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e06c291-1b9f-441d-9dfe-042ad4bd8c2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a414bc-ff46-4b72-a8c7-43c756dc89d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37741af3-69e7-4882-9d8f-9054b8f6f9f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set AWS configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b431789-31b6-4723-ab65-6bbcf76f3c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AWS_ACCESS_KEY_ID\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"AWS_SECRET_ACCESS_KEY\"\n",
    "os.environ[\"AWS_REGION\"] = \"AWS_REGION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8397ab7b-2b64-40d5-bf9e-d52c47331d0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "from botocore.client import Config\n",
    "\n",
    "# --- CONFIG ---\n",
    "VOLUME_PATH = \"/Volumes/processed/detection_data/processed_volume/output_detections_data/\"\n",
    "S3_BUCKET = \"testing-pyspark-sairam\"\n",
    "S3_REGION = \"eu-north-1\"\n",
    "ZIP_S3_KEY_PREFIX = \"detections_zipped\"\n",
    "\n",
    "# Timestamp for uniqueness\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ZIP_S3_KEY = f\"{ZIP_S3_KEY_PREFIX}/output_detections_{timestamp}.zip\"\n",
    "LOCAL_TMP_DIR = f\"/tmp/detection_output_{timestamp}\"\n",
    "LOCAL_ZIP_PATH = f\"/tmp/output_detections_{timestamp}.zip\"\n",
    "\n",
    "# --- Step 1: Prepare Local Folder ---\n",
    "if os.path.exists(LOCAL_TMP_DIR):\n",
    "    shutil.rmtree(LOCAL_TMP_DIR)\n",
    "os.makedirs(LOCAL_TMP_DIR, exist_ok=True)\n",
    "\n",
    "# --- Step 2: Collect All Parquet/CSV Files from Volume ---\n",
    "files = dbutils.fs.ls(VOLUME_PATH)\n",
    "data_files = []\n",
    "\n",
    "for folder in files:\n",
    "    if folder.name.startswith(\"file_id=\"):\n",
    "        inner_files = dbutils.fs.ls(folder.path)\n",
    "        for f in inner_files:\n",
    "            if f.path.endswith(\".parquet\") or f.path.endswith(\".csv\"):\n",
    "                data_files.append(f)\n",
    "\n",
    "print(f\"üìÅ Found {len(data_files)} data files to download.\")\n",
    "\n",
    "if not data_files:\n",
    "    raise Exception(\"‚ùå No output files found in volume!\")\n",
    "\n",
    "# --- Step 3: Download to Local ---\n",
    "for f in data_files:\n",
    "    filename = os.path.basename(f.path)\n",
    "    local_path = os.path.join(LOCAL_TMP_DIR, filename)\n",
    "    dbutils.fs.cp(f.path, f\"file:{local_path}\")\n",
    "\n",
    "print(f\"‚úÖ Downloaded all files to: {LOCAL_TMP_DIR}\")\n",
    "\n",
    "# --- Step 4: Zip All Files ---\n",
    "with zipfile.ZipFile(LOCAL_ZIP_PATH, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, files in os.walk(LOCAL_TMP_DIR):\n",
    "        for file in files:\n",
    "            abs_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(abs_path, LOCAL_TMP_DIR)\n",
    "            zipf.write(abs_path, arcname=arcname)\n",
    "\n",
    "print(f\"‚úÖ Zipped into: {LOCAL_ZIP_PATH}\")\n",
    "\n",
    "# --- Step 5: Upload ZIP to S3 ---\n",
    "s3 = boto3.client(\"s3\", region_name=S3_REGION, config=Config(signature_version=\"s3v4\"))\n",
    "s3.upload_file(LOCAL_ZIP_PATH, S3_BUCKET, ZIP_S3_KEY)\n",
    "print(f\"üöÄ Uploaded to S3: s3://{S3_BUCKET}/{ZIP_S3_KEY}\")\n",
    "\n",
    "# --- Step 6: Generate Pre-signed URL (1 Hour Validity) ---\n",
    "presigned_url = s3.generate_presigned_url(\n",
    "    \"get_object\",\n",
    "    Params={\"Bucket\": S3_BUCKET, \"Key\": ZIP_S3_KEY},\n",
    "    ExpiresIn=3600\n",
    ")\n",
    "\n",
    "print(f\"\\nüì¶ Download ZIP (valid 1 hour):\\n{presigned_url}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "S3_downloadable_link_generator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
