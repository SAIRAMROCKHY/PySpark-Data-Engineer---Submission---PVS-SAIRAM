{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b431789-31b6-4723-ab65-6bbcf76f3c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AWS_ACCESS_KEY_ID\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"AWS_SECRET_ACCESS_KEY\"\n",
    "os.environ[\"AWS_REGION\"] = \"AWS_REGION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8397ab7b-2b64-40d5-bf9e-d52c47331d0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from urllib.parse import urlparse\n",
    "from botocore.client import Config\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CONFIG ---\n",
    "s3_output_path = \"https://testing-pyspark-sairam.s3.eu-north-1.amazonaws.com/staging_data/\"\n",
    "bucket_name = \"testing-pyspark-sairam\"\n",
    "\n",
    "# Timestamp for unique filenames\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_s3_key = f\"detections_zipped/output_detections_{timestamp}.zip\"\n",
    "\n",
    "# Local temp paths (Databricks driver node)\n",
    "local_tmp_dir = f\"/tmp/detection_output_{timestamp}\"\n",
    "local_zip_path = f\"/tmp/output_detections_{timestamp}.zip\"\n",
    "\n",
    "# --- Clean and create local tmp dir ---\n",
    "if os.path.exists(local_tmp_dir):\n",
    "    shutil.rmtree(local_tmp_dir)\n",
    "os.makedirs(local_tmp_dir, exist_ok=True)\n",
    "\n",
    "# --- Parse prefix ---\n",
    "parsed = urlparse(s3_output_path)\n",
    "prefix = parsed.path.lstrip(\"/\")  # Remove leading slash\n",
    "\n",
    "# --- Initialize S3 client ---\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    region_name=\"eu-north-1\",\n",
    "    config=Config(signature_version=\"s3v4\")\n",
    ")\n",
    "\n",
    "# --- List all files using paginator ---\n",
    "paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "download_count = 0\n",
    "\n",
    "for page in pages:\n",
    "    for obj in page.get(\"Contents\", []):\n",
    "        key = obj[\"Key\"]\n",
    "        if \"_delta_log\" in key:\n",
    "            continue  # ‚ùå Skip delta log files\n",
    "        if key.endswith((\".parquet\", \".json\", \".csv\")):\n",
    "            relative_path = key[len(prefix):].lstrip(\"/\")\n",
    "            local_file_path = os.path.join(local_tmp_dir, relative_path)\n",
    "            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "            s3.download_file(bucket_name, key, local_file_path)\n",
    "            print(f\"‚¨áÔ∏è Downloaded: {key}\")\n",
    "            download_count += 1\n",
    "\n",
    "if download_count == 0:\n",
    "    print(f\"‚ùå No data files found under prefix: {prefix}\")\n",
    "    exit(1)\n",
    "\n",
    "# --- Zip downloaded files ---\n",
    "with zipfile.ZipFile(local_zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, files in os.walk(local_tmp_dir):\n",
    "        for file in files:\n",
    "            full_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(full_path, local_tmp_dir)\n",
    "            zipf.write(full_path, arcname=arcname)\n",
    "print(f\"‚úÖ Zipped {download_count} files to: {local_zip_path}\")\n",
    "\n",
    "# --- Upload ZIP to S3 ---\n",
    "s3.upload_file(local_zip_path, bucket_name, zip_s3_key)\n",
    "print(f\"‚úÖ Uploaded ZIP to s3://{bucket_name}/{zip_s3_key}\")\n",
    "\n",
    "# --- Generate pre-signed URL (valid 1 hour) ---\n",
    "url = s3.generate_presigned_url(\n",
    "    \"get_object\",\n",
    "    Params={\"Bucket\": bucket_name, \"Key\": zip_s3_key},\n",
    "    ExpiresIn=3600\n",
    ")\n",
    "print(f\"\\nüì¶ Download ZIP here (valid 1 hour):\\n{url}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "S3_downloadable_link_generator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
